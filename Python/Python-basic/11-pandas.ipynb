{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be86488-3b16-4c53-96c2-1fd7cf8d8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "\n",
      "      Name Age         City\n",
      "0    Alice  25     New York\n",
      "1      Bob  30  Los Angeles\n",
      "2  Charlie  35      Chicago\n",
      "\n",
      "\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "#A DataFrame in pandas is a two-dimensional labeled data structure, similar to a table in a database or an Excel spreadsheet. \n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print('\\n')\n",
    "import numpy as np\n",
    "data = np.array([\n",
    "    ['Alice', 25, 'New York'],\n",
    "    ['Bob', 30, 'Los Angeles'],\n",
    "    ['Charlie', 35, 'Chicago']\n",
    "])\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])\n",
    "print(df)\n",
    "print('\\n')\n",
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0d0847-f973-4745-8c81-01355f4ae591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Name gender  salary\n",
      "0           0    ayushi      F   20000\n",
      "1           1     rohit      M   25000\n",
      "2           2  pranjali      F   27000\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/vinay/Desktop/JavaScript/Python/numpy/Datasets-main/Datasets-main/company.csv\")\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6c34a-9e16-4eb2-84b1-22ba74b978c4",
   "metadata": {},
   "source": [
    "pip install openpyxl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ea1d5d-d202-42df-9018-46207cdf9280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Category       Sub-Category   Amount Payment Mode\n",
      "0  2023-01-01     Grocery             Grocery      30         Cash\n",
      "1  2023-01-02        Food          Restaurant     890          UPI\n",
      "2  2023-01-04         123              Zomato     257          NaN\n",
      "3  2023-01-06  Essentials               Diary     120          UPI\n",
      "4  2023-01-06  Essentials             Perfume    1500         Cash\n",
      "5  2023-01-09     Grocery  Fruits and Veggies     456         Cash\n",
      "6  2023-01-10       Bills          House Rent   16000          UPI\n",
      "7  2023-01-10     Grocery      Tomato KetchUp      70          UPI\n",
      "8  2023-01-12        Food                Chai      15          UPI\n",
      "9  2023-01-15  Essentials      Salt and Sugar      50          NaN\n",
      "10 2023-01-17     Grocery           Chocolate     100          UPI\n",
      "11 2023-01-17        Food          Restaurant     780         Card\n",
      "12 2023-01-18  Essentials            Food Oil     120          NaN\n",
      "13 2023-01-18        Food              Zomato     230          UPI\n",
      "14 2023-01-19     Grocery                Milk      26          UPI\n",
      "15 2023-01-20  Essentials             Shampoo     780          UPI\n",
      "16 2023-01-20  Essentials           Lunch Box     890         Cash\n",
      "17 2023-01-21     Clothes               Dress    1000          NaN\n",
      "18 2023-01-22     Clothes               Dress    1890          UPI\n",
      "19 2023-01-23     Grocery      Bread and Milk      56         Cash\n",
      "20 2023-01-24        Food  Fruits and Veggies     530         Cash\n",
      "21 2023-01-26        Food                Chai      10          UPI\n",
      "22 2023-01-26     Grocery               Maggi     140          UPI\n",
      "23 2023-01-27        Food              Zomato     300          UPI\n",
      "24 2023-01-27        Food                Chai      10          UPI\n",
      "25 2023-01-28  Essentials           Bedsheets    1025         Cash\n",
      "26 2023-01-29       Bills             Mobile     1650          UPI\n",
      "27 2023-01-29     Grocery                Daal     150         Cash\n",
      "28 2023-01-30       Bills            Cylinder    1074          UPI\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           29 non-null     datetime64[ns]\n",
      " 1   Category       29 non-null     object        \n",
      " 2   Sub-Category   29 non-null     object        \n",
      " 3   Amount         29 non-null     int64         \n",
      " 4   Payment Mode   25 non-null     object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 1.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_excel(\"C:/Users/vinay/Desktop/JavaScript/Python/numpy/Datasets-main/Datasets-main/expense3.xlsx\")\n",
    "print(df2)\n",
    "print(df2.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd30d7b-ee21-4e2a-a916-ba478506d896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2023-01-17 19:02:04.137931008</td>\n",
       "      <td>1039.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-01-10 00:00:00</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2023-01-19 00:00:00</td>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-01-26 00:00:00</td>\n",
       "      <td>890.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-01-30 00:00:00</td>\n",
       "      <td>16000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2927.684353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date        Amount\n",
       "count                             29     29.000000\n",
       "mean   2023-01-17 19:02:04.137931008   1039.620690\n",
       "min              2023-01-01 00:00:00     10.000000\n",
       "25%              2023-01-10 00:00:00     70.000000\n",
       "50%              2023-01-19 00:00:00    257.000000\n",
       "75%              2023-01-26 00:00:00    890.000000\n",
       "max              2023-01-30 00:00:00  16000.000000\n",
       "std                              NaN   2927.684353"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e479831e-539c-415d-9582-470bfad32c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Amount           0\n",
      "Payment Mode     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb41ff57-ff36-4088-99bf-cc656e6234ed",
   "metadata": {},
   "source": [
    "handling dupplicate values in datframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eed603c-8374-4d67-a584-4fbeef7ee891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/vinay/Desktop/JavaScript/Python/numpy/Datasets-main/Datasets-main/company1.csv\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90ec59f-10a5-4f83-8738-e50c64671635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df1['EEID'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b33a1c33-b06f-4da6-b60a-c687f82e02ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "941f07e4-d9ed-4caf-a942-909865833b17",
   "metadata": {},
   "source": [
    "Method\tDescription\n",
    "isna() / isnull()\tIdentify missing values.\n",
    "notna() / notnull()\tIdentify non-missing values.\n",
    "dropna()\tRemove rows/columns with missing values.\n",
    "fillna()\tFill missing values with a specific value.\n",
    "replace()\tReplace missing data with specific values.\n",
    "interpolate()\tEstimate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa7d2b4d-6271-4de8-8593-9016fde87f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "#Drop Rows with Any Missing Values\n",
    "#Drop Rows with Any Missing Values\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)\n",
    "#Drop Rows with All Missing Values\n",
    "df_cleaned = df.dropna(how='all')\n",
    "print(df_cleaned)\n",
    "#Drop Columns with Missing Values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "print(df_cleaned)\n",
    "#Drop Rows with Threshold of Non-NA Values\n",
    "df_cleaned = df.dropna(thresh=2)  # Keep rows with at least 2 non-NA values\n",
    "print(df_cleaned)\n",
    "\n",
    " students.dropna(subset =['name'],inplace=True)\n",
    "    return students #delete rows with column subset 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134d469-f4e8-4f94-ad05-31f09daf9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Missing Data\n",
    "#fillna(): Fills missing values with a specified value or method.\n",
    "df_filled = df.fillna(value={'Name': 'Unknown', 'Age': 0, 'City': 'N/A'})\n",
    "print(df_filled)\n",
    "\n",
    "#Fill with Mean, Median, or Mode\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())  # Fill with mean\n",
    "print(df)\n",
    "\n",
    "#Forward Fill (Fill with Previous Value)\n",
    "df_filled = df.fillna(method='ffill')\n",
    "print(df_filled)\n",
    "\n",
    "#Backward Fill (Fill with Next Value)\n",
    "df_filled = df.fillna(method='bfill')\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e24b2096-e150-4fa0-b17a-a78a4e21a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F   3000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali   3000  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05      3000      M  25000.0\n",
      "5  EMP06     rohit      M   3000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "#replace a missing value with any or specific value\n",
    "import numpy as np\n",
    "print(df1.replace(np.nan,3000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fde6529a-e257-4ff0-9b92-8b12fab417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['salary'] = df1[\"salary\"].replace(np.nan,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1e29478-6f48-46d8-8ce8-9647b0c2a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F   3000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M   3000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fb0cab3-e964-4e9c-9d0f-065e923e888f",
   "metadata": {},
   "source": [
    "Summary of Transformation Techniques\n",
    "Transformation Type\tMethod/Function\n",
    "Add/Modify Columns\t         df['col'] = value, assign()\n",
    "Rename Columns\t             rename()\n",
    "Apply Conditional Logic\t     apply(), np.where()\n",
    "Mathematical Operations\t     apply(), transform()\n",
    "Arithmetic operators,\n",
    " \n",
    "String Operations\t         str.upper(), str.replace(), str.extract()\n",
    "Aggregation\t            `    groupby().transform()\n",
    "Missing Value Handling\t     fillna(), dropna()\n",
    "Scaling\t                     Min-Max scaling, Standardization\n",
    "One-Hot Encoding\t         pd.get_dummies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4866e1d-5e61-4f89-a66b-996b97074077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column\n",
    "df['Country'] = 'USA'\n",
    "print(df)\n",
    "\n",
    "df['Age'] = df['Age'] + 5  # Add 5 years to each age\n",
    "print(df)\n",
    "#Rename Columns\n",
    "df.rename(columns={'City': 'Location'}, inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f2ff9-ac1b-4dc0-b370-9ed6007b9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so its like if bonus value is 0 then in tbat \n",
    "df.loc[(df[\"bonus %\"]==0),\"getbonus\"] = \"no bonus\"\n",
    "df.loc[(df[\"bonus %\"]>0),\"getbonus\"] = \"no bonus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6db34c-a466-4aed-8949-5ecd6330a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column based on a condition\n",
    "df['Senior Citizen'] = df['Age'].apply(lambda x: 'Yes' if x >= 30 else 'No')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47badb-a19e-41b5-a3c4-fecf8ac8a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].mean())  # Fill missing values with the mean\n",
    "print(df)\n",
    "\n",
    "# Add a column based on a condition\n",
    "df['Senior Citizen'] = df['Age'].apply(lambda x: 'Yes' if x >= 30 else 'No')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3969a-1616-463b-8b77-68d9b31441ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('City')['Age'].transform('mean')  # Mean age for each city\n",
    "df['City_Avg_Age'] = grouped\n",
    "print(df)\n",
    "#Group and Transform Data\n",
    "\n",
    "df['Age_Doubled'] = df['Age'].apply(lambda x: x * 2)\n",
    "print(df)\n",
    "#Apply a Function to a Column \n",
    "#Apply a Function to Multiple Columns\n",
    "def combine_name_age(row):\n",
    "    return f\"{row['Name']} ({row['Age']})\"\n",
    "\n",
    "df['Name_Age'] = df.apply(combine_name_age, axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fc49d-bcc7-4383-931e-c7130ed13ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. One-Hot Encoding for Categorical Columns\n",
    "df = pd.get_dummies(df, columns=['City'], prefix='City')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4567bf9-d9c8-4e36-8dcf-61455f23e94f",
   "metadata": {},
   "source": [
    "Transformation Type\tMethod/Function\n",
    "Add/Modify Columns\t           df['col'] = value, assign()\n",
    "Rename Columns\t               rename()\n",
    "Apply Conditional Logic\t       apply(), np.where()\n",
    "Mathematical Os\tArithmetic o   apply(), transform()\n",
    "String Operations\t           str.upper(), str.replace(), str.extract()\n",
    "Aggregation\t                   groupby().transform()\n",
    "Missing Value Handling\t       fillna(), dropna()\n",
    "Scaling\t                       Min-Max scaling, Standardization\n",
    "One-Hot Encoding\t           |pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6db0f5-f4a3-4d74-bf14-47565b7f884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          City  Population  Sales\n",
      "0     New York        8000    200\n",
      "1  Los Angeles        4000    150\n",
      "2     New York        7500    250\n",
      "3      Chicago        2700    100\n",
      "4  Los Angeles        4200    180\n",
      "City\n",
      "Chicago        100\n",
      "Los Angeles    330\n",
      "New York       450\n",
      "Name: Sales, dtype: int64\n",
      "City\n",
      "Chicago        100\n",
      "Los Angeles    180\n",
      "New York       250\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles'],\n",
    "    'Population': [8000, 4000, 7500, 2700, 4200],\n",
    "    'Sales': [200, 150, 250, 100, 180]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# Group by 'City' and calculate total sales for each city\n",
    "grouped = df.groupby('City')['Sales'].sum()\n",
    "print(grouped)\n",
    "\n",
    "g = df.groupby('City')['Sales'].max()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "990816e0-e590-42bf-b8ea-754aacdbdcc6",
   "metadata": {},
   "source": [
    "transform():\n",
    "Used with groupby() to perform operations on each group while returning a DataFrame or Series of the same shape as the original data.\n",
    "Each value in the column is replaced with the result of a group-level operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f706f3-c50c-4281-9f30-b313da663dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          City  Population  Sales  Mean_Sales_Per_City\n",
      "0     New York        8000    200                225.0\n",
      "1  Los Angeles        4000    150                165.0\n",
      "2     New York        7500    250                225.0\n",
      "3      Chicago        2700    100                100.0\n",
      "4  Los Angeles        4200    180                165.0\n"
     ]
    }
   ],
   "source": [
    "# Add a column showing the mean sales for each city\n",
    "df['Mean_Sales_Per_City'] = df.groupby('City')['Sales'].transform('mean')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fd1569b-08cc-43eb-8e0e-a79a9df3a80f",
   "metadata": {},
   "source": [
    " join()\n",
    "Combines two DataFrames based on their index.\n",
    "Default type is left join.\n",
    "df1.join(df2, how='join_type', on=key)\n",
    "how: Type of join ('left', 'right', 'outer', 'inner').\n",
    "on: Specifies columns for the join if not using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68716d8-b651-47b1-8662-cdd77373c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     Name  Score\n",
      "1   1    Alice     85\n",
      "2   2      Bob     90\n",
      "3   3  Charlie     75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}, index=[1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Score': [85, 90, 75]\n",
    "}, index=[1, 2, 3])\n",
    "\n",
    "# Join based on index\n",
    "result = df1.join(df2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "082c00e2-e007-4898-9ea4-e93e40c7203b",
   "metadata": {},
   "source": [
    "2. merge()\n",
    "Combines datasets based on one or more common columns or index.\n",
    "Flexible for one-to-one, many-to-one, and many-to-many relationships.\n",
    "pd.merge(df1, df2, how='join_type', on='column', left_on='col1', right_on='col2')\n",
    "how: Type of join ('inner', 'outer', 'left', 'right').\n",
    "on: Common column(s) for the merge.\n",
    "left_on/right_on: Use different columns from each DataFrame for joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75692d61-8eda-4ffe-b4eb-af21b572defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   Name  Score\n",
      "0   1  Alice     85\n",
      "1   2    Bob     90\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [1, 2, 4],\n",
    "    'Score': [85, 90, 88]\n",
    "})\n",
    "\n",
    "# Merge on ID\n",
    "result = pd.merge(df1, df2, how='inner', on='ID')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883e83e-dcc5-4ea2-a918-2a58ab0a1001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
